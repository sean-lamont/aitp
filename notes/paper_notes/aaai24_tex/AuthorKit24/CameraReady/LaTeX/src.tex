%File: formatting-instructions-latex-2024.tex
%release 2024.0
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage[submission]{aaai24}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
    basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
    numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
    aboveskip=0pt,belowskip=0pt,%
    showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
    /TemplateVersion (2024.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai24.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{MEDIAIT: A Modular Environment for Driving Insights in Automated Interactive Theorem-Proving}
\author{
%Authors
% All authors must be in the same font size and format.
    Written by AAAI Press Staff\textsuperscript{\rm 1}\thanks{With help from the AAAI Publications Committee.}\\
    AAAI Style Contributions by Pater Patel Schneider,
    Sunil Issar,\\
    J. Scott Penberthy,
    George Ferguson,
    Hans Guesgen,
    Francisco Cruz\equalcontrib,
    Marc Pujol-Gonzalez\equalcontrib
}
\affiliations{
%Afiliations
    \textsuperscript{\rm 1}Association for the Advancement of Artificial Intelligence\\
    % If you have multiple authors and multiple affiliations
    % use superscripts in text and roman font to identify them.
    % For example,

    % Sunil Issar\textsuperscript{\rm 2}, 
    % J. Scott Penberthy\textsuperscript{\rm 3}, 
    % George Ferguson\textsuperscript{\rm 4},
    % Hans Guesgen\textsuperscript{\rm 5}
    % Note that the comma should be placed after the superscript

    1900 Embarcadero Road, Suite 101\\
    Palo Alto, California 94303-3310 USA\\
    % email address must be in roman text type, not monospace or sans serif
    proceedings-questions@aaai.org
%
% See more examples next
}

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Multiple Authors}
\author {
% Authors
    First Author Name\textsuperscript{\rm 1,\rm 2},
    Second Author Name\textsuperscript{\rm 2},
    Third Author Name\textsuperscript{\rm 1}
}
\affiliations {
% Affiliations
    \textsuperscript{\rm 1}Affiliation 1\\
    \textsuperscript{\rm 2}Affiliation 2\\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
%\usepackage{hyperref}
% END REMOVE bibentry

\begin{document}

    \maketitle

    \begin{abstract}
        Recent interest in Artificial Intelligence for Theorem Proving (AITP) has given rise to a plethora of benchmarks and
        methodologies, particularly in the area of Interactive Theorem Proving (ITP).
        Research in the area is fragmented, with a diverse set of approaches being spread across several ITP systems.
        This presents a significant challenge to the comparison of methods, which are often complex and difficult to replicate.
        To address this, we present MEDIAIT: A Modular Environment for Driving Insights in AI for IT(P).
        By separating the learning approach from the data and ITP environment, MEDIAIT allows for the fair and efficient
        comparison of approaches between systems.
        MEDIAIT is designed to seamlessly incorporate new systems and benchmarks, currently integrating the HOList, HOLStep,
        MIZAR40, LeanStep, LeanGym and TacticZero benchmarks.
        We demonstrate the utility of MEDIAIT through a study of embedding architectures in the context of the above systems.
        % (Through comparing the performance of approaches across a variety of ITP settings, we provide strong evidence that..)
        These experiments lay the foundations for future work in evaluation of performance of formula embedding,
        while simultaneously demonstrating the capability of the framework.
        % (We show that the embedding approach of HOList applied to HOL4's TacticZero provides a significant improvement in)
        % (performance.)
        We complement these with a qualitative analysis of embeddings within and between systems, illustrating that improved
        performance was associated with more semantically aware embeddings.
        By streamlining the implementation and comparison of Machine Learning algorithms in the ITP context,
        we anticipate MEDIAIT will be a springboard for future
        research.

    \end{abstract}


    \section{Introduction}

    Interactive Theorem Proving (ITP) is a central paradigm of formal verification.
    With a human providing high level proof guidance, ITP systems have been used to write verified compilers (cite),
    formalise mathematical conjectures (cite) and develop provably correct microkernels (cite).
    As proficiency in both the formal system and application domain is needed,
    large verification projects require significant human resources and expertise.
    This restricts their scalability and widespread adoption, with for example xx taking xx amount of years.
    Advancements in Artificial Intelligence for Interactive Theorem Proving (AI-ITP) have shown potential in automating
    and assisting human ITP guidance, but there remain many challenges in the area.
    With the current state of the art achieving $42\%$ accuracy on the (highly difficult) miniF2F-curriculum benchmark (cite),
    there is still much progress to be made.
%    which is a .

%    we present a framework for rapid experimentation and development in AI-ITP.
%    We use this to unify several datasets, environments and algorithms in the area,

    To that end, it is important to efficiently and fairly compare approaches,
    which is difficult as results are fragmented across multiple ITP systems.
    Current results are evaluated either with labelled datasets extracted from proof data, as in HOLStep, LeanStep and MIZAR40,
    or through direct interaction with a proving environment.
    Environments for agent interaction have been shown to be vital in improving performance (cite),
    as they allow for the generation of new data through automated proof attempts.
    Such environments include HOList~\cite{bansal_holist_2019} for HOL Light, CoqGym for Coq (cite)
    LeanGym for Lean (cite), and INT as an AI-ITP specific (in)equality proving system.
    These provide a broad set of tasks for benchmarking, however as they are all isolated to a single system
    it is difficult to compare approaches between them.
    This is further complicated by the variety and complexity of algorithms used, which can vary over several axes.
    For example, TacticZero \cite{wu_tacticzero_2021} uses a seq2seq autoencoder for expressions,
    and learns through online Reinforcement Learning (RL) with a custom goal selection algorithm.
    \cite{bansal_holist_2019} instead use Breadth First Search (BFS) for goal selection,
    with offline learning over human and synthetic proof logs.

    Despite this, many fundamental components are common across AI-ITP systems.
    We leverage these to develop a modular, unified framework for accelerating research in the area.
    XXX brings together several environments, datasets and models from AI-ITP, with a central interface
    for running experiments and sharing components between systems.
    Being fully open source, the addition of new benchmarks and algorithms is facilitated
    by a modular and decoupled design.
    We combine this with automatic logging, checkpointing and configuration management
    to allow for rapid testing and prototyping of ideas with minimal overhead.

    A large focus of this paper is using xx to perform a comparison of embedding architectures in AI-ITP.
    ITP expressions are either treated as a natural language sequence,
    or as a directed graph derived from their abstract syntax tree representation.
    It has been argued that a graph representation is more appropriate, with a large body of work in AI-ITP
    using Graph Neural Network (GNN) as the embedding model to achieve strong results
    in several tasks\cite{wang_premise_nodate, paliwal_graph_2019, bansal_learning_2019}.
    However, Transformer models applied to the sequence representation have also demonstrated strong performance through
    leveraging large models pre-trained on NLP datasets (cite).
    Both architectures have fundamental limitations, as GNNs suffer from poor integration of global information and
    Transformers are trained without the structural information in graphs.
    The INT environment, which we include, was used to compare these approaches in a synthetic setting,
    however we extend this to a comparison across a suite of tasks in various ITPs.
    We also compare the recent SAT (cite) architecture which combines both approaches, and show ...
    Additionally, we provide a qualitative analysis supporting the intuition that better performing models
    generate more semantically aware embeddings.

%    The limited availability of quality proof data is cited as a strong limiting factor (cite).
%    There has been solid progress in the generation of quality ITP proof data, with (cite leanstep, holstep, isarstep).
%    Other benchmarks are over labelled data with respect to proxy tasks,
%    such as classifying whether a lemma was successful in the proof of a theorem (cite).

%    Current results are restricted to using only one or two
%    (cite pact) address this through a large corpus of intermediate tasks, and others (holist, leangym? hypertree, hol4)
%    use generated data from agent interaction with the proving system.
%    These approaches are split across several distinct proof systems, k

%    a consistent backend for experiments, enabling fair and efficient comparison of approaches.

%    For example, proof search, model architecture and data format are all configurable and don't require substantial code modifications.

% (still small in the context of large models and compared to NLP. )
% (Through curating these data sources into a centralised platform, we have created a large dataset  of xxx examples and xxx GB of proof data.)

    \subsection{Related Work}
    As we have highlighted, current frameworks in AI-ITP are focused on a single proving system.
    Our approach is complementary to this, and builds upon the extensive work done developing these benchmarks
    by creating a unified framework for interfacing with them.

    Similar unified frameworks have been across areas such as NLP, CV, GNN (graph benchmarks),
    which have provided strong value to their respective areas

    The most directly related to our work are MWPToolkit and LImA? for Math Word Problems (MWP),
    another area of AI for Mathematical Reasoning.
    These similarly bring together datasets and approaches across the area into a single framework.

    There are additional considerations in our case:

    \begin{itemize}
        \item Environment interaction makes it difficult to be fully decouple data and model. (e.g. HOL4 environment for TacticZero)
        \item Several axes of variation in algorithm design. Learning paradigm, proof search, embedding arch., action selection
        arch, whereas MWP focuses primarily on NLP pipelines
    \end{itemize}


    Although we focus on automating the human interaction with ITP, other approaches such as ML for Hammers (cite) have also
    provided promising directions for automated and assisting ITP proofs.


    \section{Background}

    \subsection{ITP}
% - Lean, metamath (mizar), HOL4, HOL-Light

    \subsection{Datasets and Benchmarks}
%- LeanStep, mizar40, mizar60?, HOLStep,
%- Environments
%- HOList, LeanGym, CoqGym, HOL4

    Figure x provides a summary of current datasets and benchmarks related to AI-ITP.
    Fields marked as non-interactive represent labelled datasets derived from proofs in ITP systems, an
    A common task in the literature is predicting whether a premise was useful in the proof of a given conjecture.

    % todo
    HOLStep \cite{kaliszyk_holstep_2017}, MIZAR40 \cite{kaliszyk_mizar_2015},.. provide datasets around this (ISARstep ..., look at INT paper intro)
    This is a


    LeanStep for others

    Figure (Table):
    Benchmark vs Details (size, system, interactive)
    Highlight in bold what is currently included
    Include HOL4 premise selection
    HOList, LeanStep, HOLStep, MIZAR40, LeanGym, TacticZero, (CoqGym, IsarStep etc from survey)

    As outlined in Figure x, benchmarks consider each system in isolation, and generally focus on a small set of
    learning and proof search approaches.
    Given the many differences between ITPs, this is unsurprising, as there is significant effort required to set
    up these systems for automated proving.

%HOList provides a large scale dataset and interactive environment for HOL Light, with a Breadth First Search proof large
%scale dataset and interactive environment for HOL Light, with a Breadth First Search proof
%
%and LeanStep/LeanGym are the two largest and
%


    \subsection{AI-ITP}
    \begin{figure}[h]
        \centering
        \includegraphics[width=\linewidth]{AI-ITP_colour_1.drawio}
        \caption{General Framework for AI-ITP approaches. Dashed lines represent different learning approaches,
            specifically Reinforcement Learning and Supervised Learning.
            XXX implements this through highly decoupled Data, Model and Environment modules,
            simplifying development by enabling the reuse of shared components.}
        \label{fig:ai-itp}
    \end{figure}

    \subsubsection{Problem Setup}
%    Figure \ref{fig:ai-itp} presents a general, high level framework for AI-ITP systems.
    As done in \cite{wu_tacticzero_2021}, the AI-ITP problem can be represented by a discrete Markov Decision Process (MDP),
    although our presentation here is more general to extend over multiple ITPs.
    The objective in each round is to prove an initial theorem, defined as the goal $g$.
    The initial state $s \in \mathcal{S}$ includes $g$ along with auxiliary information such as allowed premises and axioms.
    The agent $\pi$ is a mapping from the state to an action $a \in \mathcal{A}$, i.e. $\pi: \mathcal{S} \to \mathcal{A}$.
    The environment $\mathcal{E}: \mathcal{A} \to \mathcal{S}$ is a superset of the ITP system,
    taking an action $a$ to a new state $s' \in \mathcal{S}$.
    $s'$ is either a terminal state confirming the proof of the original goal,
    or represents a new state with goal(s) equivalent to proving $g$.
    $\mathcal{E}$ is effectively a wrapper over the ITP environment, and can include reward signals for reinforcement learning.
    The wrapper may also keep track of previous states such that $s'$ represents a \textit{proof tree},
    representing all current paths to proving the original goal.

    In practice, there are many choices for the learning system $\pi$, which we outline below.

    \subsubsection{Learning Approach}
    The learning paradigm is an important consideration in the design of an AI-ITP system, representing how the
    parameters of $\pi$ are updated.
    The simplest approach is direct supervised learning over proof logs.
    As shown in \ref{fig:ai-itp},
    these logs are either collected from human proofs or collected as part of the interaction of the AI system with the ITP environment.
    For the HOList benchmark,~\cite{bansal_learning_2019} demonstrate strong results with supervised training over human and synthetic logs,
    improving over~\cite{paliwal_graph_2019} which used only human proofs.
    Both approaches train a model to rank premises and tactics based on log information,
    which is then used to guide ITP interaction.

    TacticZero~\cite{wu_tacticzero_2021} learns only using synthetic proof data.
    In this case, learning is done through Reinforcement Learning with Policy Gradient,
    with the agent replaying previously recorded proof traces.
    Compared to supervised learning approaches, RL has the advantage of removing biases in the labelling of data.
    For example, it is common to assign negative labels to premises not used in an original human proof
    ~\cite{kaliszyk_holstep_2017, kaliszyk_mizar_2015, bansal_holist_2019}
    despite the potential for these premises to be useful in a different proof of the same conjecture.
    However, RL (in particular Policy Gradient) is known to suffer from high variance in the gradient updates (CITE)
    It remains unclear which approach is superior in AI-ITP, further motivating a centralised comparison platform.

    Recent advancements in NLP have led to more recent work applying pretrained language models in the context of AI-ITP.
    HyperTree, LeanStep, GPT-f, Curriculum learning
    Pre-training over proof data (PACT)
    Pre-training over NLP corpus

    \subsubsection{Proof Search}
    Proof search, represented by the goal model in \ref{fig:ai-itp}, is a core component of AI-ITP systems.
    Many approaches in the literature, including GamePad(cite), \cite{bansal_learning_2019}, (cite curriculum) apply Breadth First Search (BFS)
    to select goals. TacticZero \cite{wu_tacticzero_2021} shows an improvement over naive BFS through ablations with their fringe approach,
    which considers the likelihood of proving distinct sets of goals equivalent to the original proof.
    Improvements have also been found in (cite hypertree) through an adapted MCTS algorithm. Other approaches..?

    \subsubsection{State Embedding}
    The state embedding model converts the current proof state into a vector representation.
    An effective embedding model is important, as it is the only information used by the tactic and goal selection models.
    The form of the proof state varies between approaches and ITPs,
    however includes at least the current set of goals required to prove the initial proposition.

    For goal selection approaches such as BFS which are independent of the state embedding,
    this component reduces to embedding the expression of the selected goal.
    Other approaches such as (cite hypertree) and \cite{wu_tacticzero_2021} compute embeddings for each goal separately,
    followed by a learned model deciding the final goal from this.
    Finally, approaches such as


    For NLP models, the state is fed in natural language as a text prompt for the tactic selection model.

    \subsubsection{Tactic Selection}
    Tactic selection, along with goal selection, form the
    Fixed set of tactics/arguments (TacticZero, HOList), generative model (GPT-f, Curriculum learning, lean)

    \subsection{Embedding Architecture}

    Graph expressions in GamePad, HOLStep, HOList, MIZAR, INT, until recently were the primary representation.
    Transformers have now been a

    Transformer, GNN, SAT, Directed SAT, Autoencoder
    Figure (Table):
    Interactive Approaches vs Details
    Proof search
    BFS, MCTS, Fringe
    Embedding architecture
    GNN, Transformer, Autoencoder
    Tactic/Argument selection
    Generative (lean, hypertree), Fixed set (HOL4, HOList)
    Learning approach
    RL (TacticZero), Supervised proof logs (HOList, Lean, Hypertree?)


    \section{MEDIATE}
    Diagram and explanation of system architecture,

    Open Source additions:
    LeanGym/LeanStep output s-expressions
    HOList using non-google tools, and independent of TF1 and ML framework

    Curated, large dataset of varied ITPs

    Modular framework


    \section{Embedding Experiments}

    \subsection{Supervised}
    MIZAR, HOLStep, HOL4 pretrain, HOList Pretrain, Lean?

    \subsection{End to End}
    TacticZero, HOList?

    \subsection{Qualitative Analysis}


    \section{Discussion}


    \section{Conclusion}

%
%\section{Additional Resources}
%\LaTeX{} is a difficult program to master. If you've used that software, and this document didn't help or some items were not explained clearly, we recommend you read Michael Shell's excellent document (testflow doc.txt V1.0a 2002/08/13) about obtaining correct PS/PDF output on \LaTeX{} systems. (It was written for another purpose, but it has general application as well). It is available at www.ctan.org in the tex-archive.
%
%\appendix
%\section{Reference Examples}
%\label{sec:reference_examples}
%
%\nobibliography*
%Formatted bibliographies should look like the following examples. You should use BibTeX to generate the references. Missing fields are unacceptable when compiling references, and usually indicate that you are using the wrong type of entry (BibTeX class).
%
%\paragraph{Book with multiple authors~\nocite{em:86}} Use the \texttt{@book} class.\\[.2em]
%\bibentry{em:86}.
%
%\paragraph{Journal and magazine articles~\nocite{r:80, hcr:83}} Use the \texttt{@article} class.\\[.2em]
%\bibentry{r:80}.\\[.2em]
%\bibentry{hcr:83}.
%
%\paragraph{Proceedings paper published by a society, press or publisher~\nocite{c:83, c:84}} Use the \texttt{@inproceedings} class. You may abbreviate the \emph{booktitle} field, but make sure that the conference edition is clear.\\[.2em]
%\bibentry{c:84}.\\[.2em]
%\bibentry{c:83}.
%
%\paragraph{University technical report~\nocite{r:86}} Use the \texttt{@techreport} class.\\[.2em]
%\bibentry{r:86}.
%
%\paragraph{Dissertation or thesis~\nocite{c:79}} Use the \texttt{@phdthesis} class.\\[.2em]
%\bibentry{c:79}.
%
%\paragraph{Forthcoming publication~\nocite{c:21}} Use the \texttt{@misc} class with a \texttt{note="Forthcoming"} annotation.
%\begin{quote}
%\begin{footnotesize}
%\begin{verbatim}
%@misc(key,
%  [...]
%  note="Forthcoming",
%)
%\end{verbatim}
%\end{footnotesize}
%\end{quote}
%\bibentry{c:21}.
%
%\paragraph{ArXiv paper~\nocite{c:22}} Fetch the BibTeX entry from the "Export Bibtex Citation" link in the arXiv website. Notice it uses the \texttt{@misc} class instead of the \texttt{@article} one, and that it includes the \texttt{eprint} and \texttt{archivePrefix} keys.
%\begin{quote}
%\begin{footnotesize}
%\begin{verbatim}
%@misc(key,
%  [...]
%  eprint="xxxx.yyyy",
%  archivePrefix="arXiv",
%)
%\end{verbatim}
%\end{footnotesize}
%\end{quote}
%\bibentry{c:22}.
%
%\paragraph{Website or online resource~\nocite{c:23}} Use the \texttt{@misc} class. Add the url in the \texttt{howpublished} field and the date of access in the \texttt{note} field:
%\begin{quote}
%\begin{footnotesize}
%\begin{verbatim}
%@misc(key,
%  [...]
%  howpublished="\url{http://...}",
%  note="Accessed: YYYY-mm-dd",
%)
%\end{verbatim}
%\end{footnotesize}
%\end{quote}
%\bibentry{c:23}.
%
%For the most up to date version of the AAAI reference style, please consult the \textit{AI Magazine} Author Guidelines at \url{https://aaai.org/ojs/index.php/aimagazine/about/submissions#authorGuidelines}
%
%\section{Acknowledgments}
%AAAI is especially grateful to Peter Patel Schneider for his work in implementing the original aaai.sty file, liberally using the ideas of other style hackers, including Barbara Beeton. We also acknowledge with thanks the work of George Ferguson for his guide to using the style and BibTeX files --- which has been incorporated into this document --- and Hans Guesgen, who provided several timely modifications, as well as the many others who have, from time to time, sent in suggestions on improvements to the AAAI style. We are especially grateful to Francisco Cruz, Marc Pujol-Gonzalez, and Mico Loretan for the improvements to the Bib\TeX{} and \LaTeX{} files made in 2020.
%
%The preparation of the \LaTeX{} and Bib\TeX{} files that implement these instructions was supported by Schlumberger Palo Alto Research, AT\&T Bell Laboratories, Morgan Kaufmann Publishers, The Live Oak Press, LLC, and AAAI Press. Bibliography style changes were added by Sunil Issar. \verb+\+pubnote was added by J. Scott Penberthy. George Ferguson added support for printing the AAAI copyright slug. Additional changes to aaai24.sty and aaai24.bst have been made by Francisco Cruz, Marc Pujol-Gonzalez, and Mico Loretan.
%
%\bigskip
%\noindent Thank you for reading these instructions carefully. We look forward to receiving your electronic files!
%

    \bibliography{aaai24}

\end{document}
