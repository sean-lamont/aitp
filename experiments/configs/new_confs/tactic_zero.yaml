defaults:
  - data_config:
      - mongodb
  - data_config/data_options: graph_premise_selection
  - optimiser_config
  - logging_config

optimiser_config:
  learning_rate: 5e-5

logging_config:
  project: test
  offline: True
  id: False
  notes: ""

data_config:
  type: 'graph'
  source: 'mongodb'
  shuffle: True
  data_options:
    filter: [ 'tokens', 'edge_attr', 'edge_index' ]
    db: 'hol4_original_ast'
    expression_col: 'expression_graphs'
    vocab_col: 'vocab'
    split_col: 'paper_goals'
    environment: 'HOL4'
  #  attributes:
  #  attributes:
  # attention_edge_index: 'directed'
  # pe: 'depth'
#  dir: "data/hol4/graph_attention_data_new"

epochs: 1000

exp_config:
  name: gnn
  experiment: tactic_zero
  directory: experiments/runs/${.experiment}/${.name}_${now:%Y_%m_%d}/${now:%H_%M_%S}
  checkpoint_dir: ${.directory}/checkpoints
  accelerator: gpu
  device: [ 0 ]
  resume: False

model_config:
  vocab_size: 2200
  model_type: 'formula-net-edges'
  model_attributes:
    vocab_size: 2200
    embedding_dim: 256
    gnn_layers: 2
    batch_norm: False
  embedding_dim: 256

tactic_config:
  thms_tactic: [ "simp", "fs", "metis_tac", "rw" ] #["simp", "fs", "metis_tac"]
  thm_tactic: [ "irule", "drule" ] #["irule"]
  term_tactic: [ "Induct_on" ]
  no_arg_tactic: [ "strip_tac", "EQ_TAC" ] # ["strip_tac"]
  tactic_pool: [ "simp", "fs", "metis_tac", "rw", "irule", "drule","Induct_on","strip_tac", "EQ_TAC" ]

vocab_size: 2200
resume: False
resume_id: ""
pretrain: False
max_steps: 50
gamma: 0.99
arg_len: 5
val_freq: 5
#checkpoint_dir:
proof_db: [ 'hol4', 'proof_logs' ]
pretrain_ckpt: ""

hydra:
  run:
    dir: ${exp_config.directory}
  job:
    chdir: False